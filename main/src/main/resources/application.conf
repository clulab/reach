#
# Main Configuration file for Reach.
#

# Default top-level root directory for input and output files and subdirectories.
# All other paths are based on this path but any or all can be changed individually:
rootDir = ${user.home}/Documents/reach

# this is where the brat standoff and text files are dumped
# if this directory does not exist it will be created
bratDir = ${rootDir}/brat

# this is where the context files will be stored
# if this directory does not exist it will be created
contextDir = ${rootDir}/context

# this is where the output files containing the extracted mentions will be stored
# if this directory does not exist it will be created
outDir = ${rootDir}/output

# this is the directory that stores the raw nxml, .csv, and/or .tsv files
# this directory *must* exist
papersDir = ${rootDir}/papers


# the encoding of input and output files
encoding = "utf-8"

# this is a list of sections that we should ignore
ignoreSections = ["references", "materials", "materials|methods", "methods", "supplementary-material"]

# the output formats for mentions:
# "arizona" (column-based, one file per paper)
# "cmu" (column-based, one file per paper)
# "fries" (multiple JSON files per paper)
# "serial-json" (JSON serialization of mentions data structures. LARGE output!)
# "text" (non-JSON textual format)
outputTypes = ["fries", "arizona", "cmu"]

# number of simultaneous threads to use for parallelization
threadLimit = 2

# verbose logging
verbose = true

# whether or not assembly should be run
withAssembly = false


# context engine configuration
contextEngine {
  type = Policy4
  params = {
    bound = 3
  }
}

polarity {
  engine = DeepLearning //Hybrid//DeepLearning //Linguistic
  negCountThreshold = 1 // when lower than or equal to this value, use linguistic approach in hybrid method
  maskOption = tag //tag_name //name //tag
  savedModel = main/src/main/resources/SavedLSTM_WideBound_u_t_do_nochar // SavedLSTM // SavedLSTM_WideBound

  spreadsheetPath = main/src/main/resources/SentencesInfo_all_label_final_ExactRecur_ExpandBound_universal_temp.txt
  VOC_SIZE = 3671
  WEM_DIMENSIONS = 100
  CEM_DIMENSIONS = 30
  NUM_LAYERS = 1
  HIDDEN_SIZE = 30
  MLP_HIDDEN_SIZE = 10
  N_EPOCH = 7
  //engine = Linguistic
}

experimentalRegulation{
  keywords = main/src/main/resources/experimental_regulation_type_keywords.csv
}

# grounding configuration
grounding: {
  # List of AdHoc grounding files to insert, in order, into the grounding search sequence.
  # Each element of the list is a map of KB filename and optional meta info (not yet used):
  #   example: { kb: "adhoc.tsv", source: "NMZ at CMU" }
  adHocFiles: [
    { kb: "NER-Grounding-Override.tsv.gz", source: "MITRE/NMZ/BG feedback overrides" }
  ]

  # flag to turn off the influence of species on grounding
  overrideSpecies = true
}

# logging configuration
logging {
  # defines project-wide logging level
  loglevel = INFO
  logfile = ${rootDir}/reach.log
}

# Processor Annotator choice and configuration
processorAnnotator {
  // select which processor annotator type to use: "bionlp", "clu", "clubio", or "server"
  type = "bionlp"
}

# restart configuration
restart {
  # restart allows batch jobs to skip over input files already successfully processed
  useRestart = true
  # restart log is one filename per line list of input files already successfully processed
  logfile = ${outDir}/restart.log
}

# ReadPapers
ReadPapers.papersDir = src/test/resources/inputs/nxml/
ReadPapers.serializedPapers = mentions.ser
