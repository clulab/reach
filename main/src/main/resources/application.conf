#
# Main Configuration file for Reach.
#

# Default top-level root directory for input and output files and subdirectories.
# All other paths are based on this path but any or all can be changed individually:
rootDir = ${user.home}/Documents/reach

# this is where the brat standoff and text files are dumped
# if this directory does not exist it will be created
bratDir = ${rootDir}/brat

# this is where the context files will be stored
# if this directory does not exist it will be created
contextDir = ${rootDir}/context

# this is where the output files containing the extracted mentions will be stored
# if this directory does not exist it will be created
outDir = ${rootDir}/output

# this is the directory that stores the raw nxml, .csv, and/or .tsv files
# this directory *must* exist
papersDir = ${rootDir}/papers


# the encoding of input and output files
encoding = "utf-8"

# this is a list of sections that we should ignore
ignoreSections = ["references", "supplementary-material"]#["references", "materials", "materials|methods", "methods", "supplementary-material"]

# the output formats for mentions:
# "fries" (multiple JSON files per paper)
# "serial-json" (JSON serialization of mentions data structures. LARGE output!)
# "text" (non-JSON textual format)
# "indexcard" (Index cards)
# "assembly-tsv" (assembly output)
# "arizona" (Arizona's custom tabular output for assembly)
# "cmu" (CMU's custom tabular output for assembly)
outputTypes = ["arizona"]#["fries", "cmu", "serial-json", "indexcard", "arizona", "text"]

# number of simultaneous threads to use for parallelization
threadLimit = 2

# verbose logging
verbose = true

# whether or not assembly should be run
withAssembly = false

# context engine configuration
contextEngine {
  type = Policy4
  params = {
    bound = 3
  }
}

polarity {
  engine = Hybrid //Hybrid//DeepLearning //Linguistic
  negCountThreshold = 1 // when lower than or equal to this value, use linguistic approach in hybrid method
  maskOption = tag //tag_name //name //tag
  savedModel = SavedLSTM_WideBound_u // SavedLSTM // SavedLSTM_WideBound
  w2i = /lstmPolarityW2i.txt // save the word to index dictionary of the lstm polarity classifier.
  c2i = /lstmPolarityC2i.txt // save the character to index dictionoary of the lstm polarity classifier.
  dynetMem =  2048 // number should be in MB, clipped to 3072 Mb by the classifier.


  spreadsheetPath = /SentencesInfo_all_label_final_ExactRecur_ExpandBound_universal.txt
  VOC_SIZE = 3671
  WEM_DIMENSIONS = 100
  CEM_DIMENSIONS = 30
  NUM_LAYERS = 1
  HIDDEN_SIZE = 30
  MLP_HIDDEN_SIZE = 10
  N_EPOCH = 3
  //engine = Linguistic
}

experimentalRegulation{
  keywords = /experimental_regulation_type_keywords.csv // This is a resource!
}

# grounding configuration
grounding: {
  # List of AdHoc grounding files to insert, in order, into the grounding search sequence.
  # Each element of the list is a map of KB filename and optional meta info (not yet used):
  #   example: { kb: "adhoc.tsv", source: "NMZ at CMU" }
  adHocFiles: [
    { kb: "NER-Grounding-Override.tsv", source: "MITRE/NMZ/BG feedback overrides" }
  ]

  # flag to turn off the influence of species on grounding
  overrideSpecies = true
}

# logging configuration
logging {
  # defines project-wide logging level
  loglevel = INFO
  logfile = ${rootDir}/reach.log
}

# restart configuration
restart {
  # restart allows batch jobs to skip over input files already successfully processed
  useRestart = true
  # restart log is one filename per line list of input files already successfully processed
  logfile = ${outDir}/restart.log
}

# ReadPapers
ReadPapers.papersDir = src/test/resources/inputs/nxml/
ReadPapers.serializedPapers = mentions.ser
